# ============================================
# PRODUCTION-GRADE DOCKER COMPOSE
# Temple Crowd Management System
# ============================================

services:
  # ==========================================
  # 1. MongoDB Database (with Authentication)
  # ==========================================
  mongo:
    image: mongo:7
    container_name: temple-mongo
    restart: always
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_DATABASE=temple_db
    volumes:
      # DATA PERSISTENCE - Never lose data!
      - mongo_data:/data/db
      - mongo_config:/data/configdb
      # Backup directory (optional - mount local folder for backups)
      # - ./backups/mongo:/backup
    networks:
      - temple-network
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    # Resource limits for stability
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================
  # 2. Redis Cache (with Persistence)
  # ==========================================
  redis:
    image: redis:7-alpine
    container_name: temple-redis
    restart: always
    ports:
      - "6379:6379"
    # Enable persistence with both RDB and AOF
    command: >
      redis-server  --appendonly yes  --appendfsync everysec --save 60 1000 --save 300 100 --save 900 1 --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      # REDIS PERSISTENCE - Crowd counts will survive restart
      - redis_data:/data
    networks:
      - temple-network
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================
  # 3. ML Crowd Detection Service (YOLOv8)
  # ==========================================
  ml-detection:
    build:
      context: ./ml-services/crowd-detection
      dockerfile: Dockerfile
    container_name: temple-ml-detection
    restart: always
    ports:
      - "8001:8000"
    networks:
      - temple-network
    volumes:
      - ./ml-services/crowd-detection/models:/app/models
    environment:
      - MODEL_PATH=/app/models
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================
  # 4. ML Demand Forecasting Service (LSTM)
  # ==========================================
  ml-forecasting:
    build:
      context: ./ml-services/demand-forecasting
      dockerfile: Dockerfile
    container_name: temple-ml-forecasting
    restart: always
    ports:
      - "8002:8000"
    networks:
      - temple-network
    volumes:
      - ./ml-services/demand-forecasting/models:/app/models
    environment:
      - MODEL_PATH=/app/models
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================
  # 5. Backend API (Production-Grade)
  # ==========================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: temple-backend
    restart: always
    ports:
      - "5000:5000"
    environment:
      # Docker Network URLs (override local .env)
      - NODE_ENV=production
      - MONGO_URI=mongodb://mongo:27017/temple_db
      - MONGODB_URI=mongodb://mongo:27017/temple_db
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_URL=redis://redis:6379
      - ML_DETECTION_URL=http://ml-detection:8000
      - ML_FORECASTING_URL=http://ml-forecasting:8000
      - AI_SERVICE_URL=http://ml-forecasting:8000
      - JWT_SECRET=temple_crowd_jwt_secret_change_in_production
      # Graceful shutdown timeout
      - SHUTDOWN_TIMEOUT=10000
    depends_on:
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - temple-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5000/" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Graceful shutdown
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

# ==========================================
# NETWORKS
# ==========================================
networks:
  temple-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16

# ==========================================
# VOLUMES (Named for Persistence)
# ==========================================
volumes:
  # MongoDB data - CRITICAL: Contains all temples, bookings, users
  mongo_data:
    name: temple-mongo-data

  # MongoDB config
  mongo_config:
    name: temple-mongo-config

  # Redis data - Contains live crowd counts
  redis_data:
    name: temple-redis-data
